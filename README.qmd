---
title: "Projecting PCFG Gray Whale Abundance"
subtitle: "Model selection and evaluation"
format: 
   gfm:
     html-math-method: 
       method: webtex
       url: https://latex.codecogs.com/png.image?%5Cbg_black&space;
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}

# Load required packages -------------------------------------------------------

library(pacman)
p_load(cmdstanr, tidyverse, here, tidybayes, brms, bayesplot, knitr, kableExtra)
#set_cmdstan_path("~/cmdstan")  # your `cmdstan` path may be different

# Initialize -------------------------------------------------------------------

# Data import
source(here("R", "read_abun_retro.R"))     #; Ndata; tail(Ndata)  # Check
source(here("R", "read_calf_enp_retro.R")) #; Cdata; tail(Cdata)  # Check
source(here("R", "read_strand_retro.R"))   #; Sdata; tail(Sdata)  # Check

# Abundance Estimates
Ndata_input = filter(Ndata, year >= 2002) #; tail(Ndata_input)  # Check

# SWFSC ENP calf estimates
Cdata_input = filter(Cdata, year >= 2002) #; tail(Cdata_input)  # Check
Cdata_2020 <- Cdata_input %>%             # Impute mean of shoulder years for missing 2020 data
  slice(1) %>%
  mutate_all(~ NA) %>%
  mutate(
    year = 2020, method = "Mean of 2019 & 2021",
    mean_log = Cdata_input %>% filter(year >= 2019 & year <= 2021) %>% pull(mean_log) %>% mean(),
    sd_log = Cdata_input %>% filter(year >= 2019 & year <= 2021) %>% pull(sd_log) %>% mean()
  )

Cdata_input <- Cdata_input %>%
  add_row(Cdata_2020) %>%
  arrange(year)

# Covariate data (point estimates only) on lambda; at present, 
# not the precise time series and should be viewed as a filler for model development
x_lambda = data.frame(
  N_pcfg_calves = c(4,5,3,0,3,2,1,4,6,12,14,17,12,7,4,4,2,4,5,2, # abundance data years
                   0,0,0), # projected years, real values exist.
  N_strandings = Sdata %>% filter(state == "All" & year >= 2002) %>% pull(N_strand) %>% c(., 40) # This last value is not real!
)
x_lambda[,1] = scale(x_lambda[,1])

# Define harvest data
N_harvest = c(0,0,0)

# Input data -------------------------------------------------------------------
init_pcfg_data_3yr = list(
  n_dat_yrs = nrow(Ndata_input),  
  n_proj_yrs = 3,                      # number of years to project into the future
  n_betas = ncol(x_lambda),            # number of coefficients on lambda
  mu_logN_hat = Ndata_input$mean_log,  # estimated pop abundance, log space
  sigma_logN_hat = Ndata_input$sd_log,
  mu_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(mean_log),       # estimated ENP calf abundance, log space
  sigma_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(sd_log),
  mu_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(mean_log),  # estimated contemporary ENP calf abundance, log space
  sigma_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(sd_log),
  x_lambda_dat = as.matrix(x_lambda %>% slice(1:nrow(Ndata_input))),
  x_lambda_proj = as.matrix(x_lambda %>% slice(-c(1:nrow(Ndata_input)))),
  N_harvest = N_harvest
)

init_pcfg_data_2yr = list(
  n_dat_yrs = nrow(Ndata_input),  
  n_proj_yrs = 2,                      # number of years to project into the future
  n_betas = ncol(x_lambda),            # number of coefficients on lambda
  mu_logN_hat = Ndata_input$mean_log,  # estimated pop abundance, log space
  sigma_logN_hat = Ndata_input$sd_log,
  mu_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(mean_log),       # estimated ENP calf abundance, log space
  sigma_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(sd_log),
  mu_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(mean_log),  # estimated contemporary ENP calf abundance, log space
  sigma_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(sd_log),
  x_lambda_dat = as.matrix(x_lambda %>% slice(1:nrow(Ndata_input))),
  x_lambda_proj = as.matrix(x_lambda %>% slice(-c(1:nrow(Ndata_input)))),
  N_harvest = N_harvest[1:2]
)

init_pcfg_data_2yr_calves = list(
  n_dat_yrs = nrow(Ndata_input),  
  n_proj_yrs = 2,                      # number of years to project into the future
  n_betas = 1,            # number of coefficients on lambda
  mu_logN_hat = Ndata_input$mean_log,  # estimated pop abundance, log space
  sigma_logN_hat = Ndata_input$sd_log,
  mu_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(mean_log),       # estimated ENP calf abundance, log space
  sigma_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(sd_log),
  mu_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(mean_log),  # estimated contemporary ENP calf abundance, log space
  sigma_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(sd_log),
  x_lambda_dat = as.matrix(x_lambda %>% dplyr::select(N_pcfg_calves) %>% dplyr::slice(1:nrow(Ndata_input))),
  x_lambda_proj = as.matrix(x_lambda %>% dplyr::select(N_pcfg_calves) %>% slice(-c(1:nrow(Ndata_input)))),
  N_harvest = N_harvest[1:2]
)

init_pcfg_data_2yr_strands = list(
  n_dat_yrs = nrow(Ndata_input),  
  n_proj_yrs = 2,                      # number of years to project into the future
  n_betas = 1,            # number of coefficients on lambda
  mu_logN_hat = Ndata_input$mean_log,  # estimated pop abundance, log space
  sigma_logN_hat = Ndata_input$sd_log,
  mu_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(mean_log),       # estimated ENP calf abundance, log space
  sigma_logC_hat = Cdata_input %>% slice(1:nrow(Ndata_input)) %>% pull(sd_log),
  mu_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(mean_log),  # estimated contemporary ENP calf abundance, log space
  sigma_logC_proj = Cdata_input %>% slice(-c(1:nrow(Ndata_input))) %>% pull(sd_log),
  x_lambda_dat = as.matrix(x_lambda %>% dplyr::select(N_strandings) %>% dplyr::slice(1:nrow(Ndata_input))),
  x_lambda_proj = as.matrix(x_lambda %>% dplyr::select(N_strandings) %>% slice(-c(1:nrow(Ndata_input)))),
  N_harvest = N_harvest[1:2]
)
```

```{r models, echo = FALSE, warning = FALSE, message = FALSE}

# STAN model definitions -------------------------------------------------------
# models <- list.files("./STAN", "*.stan$")
f_pcfg_base <- here::here('STAN', 'pcfg_lognorm_base.stan')
f_pcfg_ar1v1 <- here::here('STAN', 'pcfg_lognorm_ar1_v1.stan')
f_pcfg_ar1v2 <- here::here('STAN', 'pcfg_lognorm_ar1_v2.stan')
f_pcfg_enp <- here::here('STAN', 'pcfg_lognorm_enp_calves.stan')
f_pcfg_covs <- here::here('STAN', 'pcfg_lognorm_covs.stan')
model_names <- factor(c("Base", "AR1v1", "AR1v2", "ENP Calves", 
                        "Calves only", "Strandings only", "Calves/Strandings"), 
                        levels = c("Base", "AR1v1", "AR1v2", "ENP Calves", 
                                   "Calves only", "Strandings only", "Calves/Strandings"),
                        labels = c("Base", "AR1v1", "AR1v2", "ENP Calves","PCFG Calves only", "ENP Strandings only", "PCFG Calves + ENP Strandings"))

# Model file pointers
models <- list(f_pcfg_base, f_pcfg_ar1v1, f_pcfg_ar1v2, f_pcfg_enp, 
               f_pcfg_covs, f_pcfg_covs, f_pcfg_covs)

# Specify input data
init_data <- list(init_pcfg_data_3yr, init_pcfg_data_3yr, init_pcfg_data_3yr,
                  init_pcfg_data_2yr, 
                  init_pcfg_data_2yr_calves, init_pcfg_data_2yr_strands,
                  init_pcfg_data_2yr)

# Compile models ---------------------------------------------------------------
cmodels <- purrr::map(models, cmdstanr::cmdstan_model, .progress = T)

# MCMC -------------------------------------------------------------------------
mfit <- purrr::map2(cmodels, init_data, \(x, i) x$sample(
  data = i,
  output_dir = here("out"),
  seed = 42,
  chains = 3,
  parallel_chains = 3,
  #iter_warmup = 6000, iter_sampling = 9000,
  adapt_delta = 0.99,
  show_messages = FALSE,
  show_exceptions = FALSE
))

# Prepping data for output -----------------------------------------------------
# Tidy draws
tfit = purrr::map(mfit, tidy_draws, .progress = T)
np <- purrr::map(mfit, nuts_params, .progress = T)

# Specify tresholds ------------------------------------------------------------
threshold_N = 192    # Threshold on abundance below which a hunt is closed
threshold_Nmin = 171 # Threshold on minimum abundance below which a hunt is closed
```

# Description of model set

The abundance of gray whales within the Pacific Coast Feeding Group (PCFG) - a subset of the broader Eastern North Pacific (ENP) population - is estimated within a Jolly-Seber modeling framework using data derived from yearly mark-resight surveys (Harris et al. 2024). Due to the time required to match individuals from many hundreds of sightings each year to an extensive photographic catalog, the most recent abundance estimates often lag behind the current calendar year by one or more years. However, management decisions are contingent upon abundance estimates for PCFG gray whales through the current calendar year or into the next. To meet this need, we implemented a Bayesian state-space model (SSM) to predict abundance beyond the last year for which PCFG abundance was estimated. The SSM models abundance in log-space with Gaussian errors and can be defined as the following:

*Observation process:*

$$
logN_{est} \sim normal(logN, \sigma_{obs})
$$

*State process:*

$$
logN_{est_{t+1}} = logN_{est_{t}} + ln(\lambda_{t})
$$

$$
ln(\lambda_{t}) \sim normal(\mu, \sigma)
$$

Where $logN$ and $\sigma_{obs}$ are the estimated (log) population abundance and standard error for each year with observation data, respectively. Models vary by the specification of $\lambda$ and the factors hypothesized to be correlated with population growth, at least given current knowledge and available data within this system. At present, seven models were considered.

1.  Base: $\mu = \mu_{ln(\lambda)}; \sigma = \sigma_{ln(\lambda)}$
2.  AR1v1: $\mu = ln(\lambda_{t-1}); \sigma = \sigma_{ln(\lambda)}$
3.  AR2v2: $\mu = \mu_{ln(\lambda)} + ln(\lambda_{t-1}) * \beta; \sigma = \sigma_{ln(\lambda)}$
4.  ENP calves: $\mu = \mu_{ln(\lambda)} + \beta_{calves} * C_{t}; \sigma = \sigma_{ln(\lambda)}$
5.  (PCFG) Calves only: $\mu = \mu_{ln(\lambda)} + \beta_{calves} * C_{t}; \sigma = \sigma_{ln(\lambda)}$
6.  (ENP) Strandings only: $\mu = \mu_{ln(\lambda)} + \beta_{strand} * S_{t}; \sigma = \sigma_{ln(\lambda)}$
7.  (PCFG) Calves + Strandings: $\mu = \mu_{ln(\lambda)} + \beta_{calves} * C_{t} + \beta_{strand} * S_{t}; \sigma = \sigma_{ln(\lambda)}$

<!--#

1. Base: $ln(\lambda_{t}) \sim normal(\mu_{ln(\lambda)}, \sigma_{ln(\lambda)})$ 
2. AR1v1: $ln(\lambda_{t}) \sim normal(ln(\lambda_{t-1}), \sigma_{ln(\lambda_{t})})$ 
3. AR2v2: $ln(\lambda_{t}) \sim normal(\mu_{ln(\lambda_{t})} + ln(\lambda_{t-1}) * \beta, \sigma_{ln(\lambda_{t})})$ 
4. ENP calves: $ln(\lambda_{t}) \sim normal(\mu_{ln(\lambda_{t})} + C_{t} * \beta_{calves}, \sigma_{ln(\lambda_{t})})$ 
5. (PCFG) Calves only: $ln(\lambda_{t}) \sim normal(\mu_{ln(\lambda_{t})} + C_{t} * \beta_{calves}, \sigma_{ln(\lambda_{t})})$ 
6. (ENP) Strandings only: $ln(\lambda_{t}) \sim normal(\mu_{ln\lambda} + S_{t} * \beta_{strand}, \sigma_{ln\lambda})$ 
7. (PCFG) Calves + Strandings: $ln(\lambda_{t}) \sim normal(\mu_{ln(\lambda_{t})} + C_{t} * \beta_{calves} + S_{t} * \beta_{strand}, \sigma_{ln(\lambda_{t})})$

-->

$C_{t}$ corresponds the number of calves in year *t* (either ENP or PCFG); $S_{t}$ corresponds to the number of ENP strandings in year *t*.

### Additional prior specifications

Where appropriate, the following weakly informative hyper-priors were implemented for both mean and scale parameters in the $ln(\lambda)$ priors.

$$
\mu_{ln(\lambda)} \sim normal(0, 1)
$$

$$
\sigma_{ln(\lambda)} \sim lognormal(0, 1)
$$

Importantly, $\sigma_{ln(\lambda_{t})}$ is constrained to be positive. For models with beta coefficients (models 4 - 7), additional normal priors are specified for each coefficient, *i* (e.g., $ln(\lambda_{t-1})$, ENP calves, PCFG calves, or number of strandings). At present, no hyper-priors were used for coefficients.

$$
\beta_i \sim normal(0, 1)
$$

# Model fitting diagnostics

The table below provides various chain-specific diagnostics by model specification. Chains with few to no divergences (num_divergent) and that do not hit maximum tree depth (num_max_treedepth) indicate adequate sampling of posteriors and overall good chain performance. Similarly, an estimated Bayesian fraction of missing information (ebfmi) greater than 0.3 suggests reliable inference can be drawn from posterior estimates.

```{r modelDiagnostics, echo = FALSE, warning = FALSE, message = FALSE}
#| label: tbl-diags
#| tbl-cap: "Chain diagnostics by model specification."

tab_diag_summ <- purrr::map_dfr(mfit, \(x) {
  i <- x$diagnostic_summary()
  do.call(cbind, i) %>% 
    as.data.frame() %>% 
    add_column(chain = 1:3, .before = 1)
}) %>%
  add_column(
    Model = rep(model_names, each = 3),
    .before = 1
  )

# HTML table output
# DT::datatable(tab_diag_summ, 
#               rownames = F,
#           options = list(
#             columnDefs = list(list(className = 'dt-center', targets = 1:4))
#             )) %>%
#   DT::formatRound(2:5, 2)

# For GFM-based readme
knitr::kable(
  tab_diag_summ,
  digits = 2,
  row.names = F,
  align = c("l", rep("c", 4)),
  format = "simple",
  booktabs = T
) #%>%
#kable_classic(full_width = F, html_font = "Cambria")
```

# Model results

## Coefficient estimates

$\beta$ coefficient estimates for models where coefficients on $\lambda$ were estimated. $lo\_ci$ and $hi\_ci$ correspond to the lower and upper 95% credible intervals. $Rhat$ values less than 1.01 indicate effective mixing within and across chains, producing reliable and consistent estimates for the parameters. $ess$ is the effective sample size and is an indicator of chain sampling efficiency. Here, $ess$ values greater than 300 indicate sufficient sampling has been achieved.

```{r, echo = FALSE, warning = FALSE, message = FALSE}

#coefs <- tidy_coefs(mfit, model_names)

coefs <- purrr::imap(mfit, ~ .x$summary() %>%
                     mutate(model = model_names[.y]) %>%
                     filter(grepl("beta", variable)))

coefs_tab <- do.call('rbind', coefs) %>%
    dplyr::select(model, variable, mean, median, sd, lo_ci = q5, hi_ci = q95, rhat, ess_bulk) %>%
    mutate(
      variable = c('$\\beta_{ln(\\lambda)}$', '$\\beta_{Calves}$', '$\\beta_{Calves}$', '$\\beta_{Strandings}$', '$\\beta_{Calves}$', '$\\beta_{Strandings}$')
    )

kable(coefs_tab,
  digits = c(rep(0, 2), rep(3, 6), 1),
  row.names = F,
  align = c("l", rep("c", 8)),
  format = "simple",
  booktabs = T)
```

## Leave-one-out Cross Validation (LOO)

Derived estimates of model fit using an information criterion based on leave-one-out cross validation (looic). Models with the lowest $looic$ value are considered the best fitting model given the time series of abundance data used to fit the model. $\Delta looic$ represents the difference in $looic$ relative to the model with the lowest $looic$.

```{r loo, echo = FALSE, warning = FALSE, message = FALSE}
#| label: tbl-loo
#| tbl-cap: "Derived estimates of model fit using an information criterion based on leave-one-out cross validation (looic)."

loo_pcfg <- purrr::map(mfit, \(x) x$loo(cores = 4))
#purrr::map(loo_pcfg, plot)

tab_loo <- purrr::map_dfr(loo_pcfg, \(x) t(x$estimates)[1, ]) %>%
  add_column(
    Model = model_names,
    .before = 1
  ) %>% 
  arrange(looic) %>%
  mutate(
    deltaLooic = looic - min(looic)
  )

# HTML table output
# DT::datatable(tab_loo, 
#               rownames = F,
#           options = list(
#             dom = 't',
#             columnDefs = list(list(className = 'dt-center', targets = 1:4))
#             )) %>%
#   DT::formatRound(2:5, 2)

# For GFM-based readme
knitr::kable(
  tab_loo,
  digits = 2,
  align = c("l", rep("c", 4)),
  format = "simple",
  booktabs = T
) #%>%
#kable_classic(full_width = F, html_font = "Cambria")
```

## Predictive accuracy with retrospection

Model fit statistics for predicting one year forward for all data years from 2002 through 2021. RSS is the residual sum of squares.

```{r retro1, echo = F, warning = F, message = F}
#| label: tbl-retro1
#| tbl-cap: "Model fit statistics for predicting one year forward for all data years from 2002 through 2021. RSS is the residual sum of squares."

# Retrospective prediction -----------------------------------------------------
N_eval_table <- pred_summary_tbl_multimodel(Ndata_input, tfit, model_names, threshold_N, threshold_Nmin)

# Summary stats
N_eval_summary_proj1yr <- N_eval_table %>%
  filter(proj_set == "pyear1") %>%
  group_by(model) %>%
  summarize(
    mnRSS = mean(rss),
    mean = mean(percentile_abundEstN),
    median = median(percentile_abundEstN),
    lo_ci = quantile(percentile_abundEstN, 0.025),
    hi_ci = quantile(percentile_abundEstN, 0.975),
    mnProp_below_threshold = mean(prop_below_threshold),
    mnProp_below_minThreshold = mean(prop_below_minThreshold),
    Nclosures = sum(closure)
  ) %>%
  arrange(mnRSS)

N_eval_summary_proj2yr <- N_eval_table %>%
  filter(proj_set == "pyear2") %>%
  group_by(model) %>%
  summarize(
    mnRSS = mean(rss),
    mean = mean(percentile_abundEstN),
    median = median(percentile_abundEstN),
    lo_ci = quantile(percentile_abundEstN, 0.025),
    hi_ci = quantile(percentile_abundEstN, 0.975),
    mnProp_below_threshold = mean(prop_below_threshold),
    mnProp_below_minThreshold = mean(prop_below_minThreshold),
    Nclosures = sum(closure)
  ) %>%
  arrange(mnRSS)

# HTML table output
# DT::datatable(N_eval_summary_proj1yr, 
#               rownames = F,
#               colnames = c("Model", "Mean RSS", "Mean Percentile (N)", 
#                            "Prop Below Threshold (N)", 
#                            "Prop Below Threshold (Nmin)",
#                            "Number of Closures"),
#           options = list(
#             dom = 't',
#             columnDefs = list(list(className = 'dt-center', targets = 1:5))
#             )) %>%
#   DT::formatRound(3:5, 3) %>%
#   DT::formatRound(2, 1)

# For GFM-based readme
knitr::kable(
  N_eval_summary_proj1yr,
  row.names = F,
  col.names = c("Model", "Mean RSS", "Mean Percentile (N)",
                "Median Percentile (N)",
                "Lower 95% CI for Percentile (N)",
                "Upper 95% CI for Percentile (N)",
                "Prop Below Threshold (N)",
                "Prop Below Threshold (Nmin)",
                "Number of Closures"),
  digits = 3,
  align = c("l", rep("c", 8)),
  #format = "simple",
  booktabs = T
) #%>%
#kable_classic(full_width = F, html_font = "Cambria")
```

Model fit statistics for predicting two years forward for all data years from 2002 through 2021. RSS is the residual sum of squares.

```{r retro2, echo = F, warning = F, message = F}
#| label: tbl-retro2
#| tbl-cap: "Model fit statistics for predicting two years forward for all years from 2002 through 2021. RSS is the residual sum of squares."

# HTML table output
# DT::datatable(N_eval_summary_proj2yr, 
#               rownames = F,
#               colnames = c("Model", "Mean RSS", "Mean Percentile (N)", 
#                            "Prop Below Threshold (N)", 
#                            "Prop Below Threshold (Nmin)",
#                            "Number of Closures"),
#           options = list(
#             dom = 't',
#             columnDefs = list(list(className = 'dt-center', targets = 1:5))
#             )) %>%
#   DT::formatRound(3:5, 3) %>%
#   DT::formatRound(2, 1)

# For GFM-based readme
knitr::kable(
  N_eval_summary_proj2yr,
  row.names = F,
  col.names = c("Model", "Mean RSS", "Mean Percentile (N)",
                "Median Percentile (N)",
                "Lower 95% CI for Percentile (N)",
                "Upper 95% CI for Percentile (N)",
                "Prop Below Threshold (N)",
                "Prop Below Threshold (Nmin)",
                "Number of Closures"),
  digits = 3,
  align = c("l", rep("c", 8)),
  #format = "simple",
  booktabs = T
) #%>%
#kable_classic(full_width = F, html_font = "Cambria")
```

```{r retroFig, echo = F, warning = F, message = F, fig.height = 8, fig.width = 10, dpi = 300}
# Figure
tidy_plot_retroPred(N_eval_table)
```

## Model-specific trends and projections

Note, the number of PCFG calves used in projected years (models Calves/Strandings and Calves only) are not accurate and likely represent underestimates of reality.

```{r trendFig, echo = F, warning = F, message = F, fig.height = 18, fig.width = 8, dpi = 300}
# Population trajectories ------------------------------------------------------
tidy_plot_traj_multimodel(Ndata_input, tfit, model_names, threshold_N, threshold_Nmin, ncols = 1)
```

## Model-specific predictions for Y~final~ + 2

```{r finalEstimates, echo = F, warning = F, message = F, fig.height = 4, fig.width = 8, dpi = 300}
#| label: fig-final-proj
#| fig-cap: "Model-specific estimated abundance in the second year of projections (Year 2024). Mean estimates are represented by vertical dashed lines in the corresponding colors. The black and red ticks along the x-axis (rugs) correspond to the management closure thresholds for N and N minimum, respectively."
#| 
# Projected estimated final abundance + 2 years --------------------------------
#lastYr <- paste0("logN[", nrow(Ndata_input), "]")
lastYr <- "logN_proj[2]"
postLastYr <- purrr::imap(tfit, ~.x[lastYr] %>% add_column(Model = model_names[.y]))
postLastYr <- do.call(rbind, postLastYr)
           

postLastYr_mns <- postLastYr %>%
  group_by(Model) %>%
  summarize(
    Nmean = exp(mean(`logN_proj[2]`))
  )

ggplot(postLastYr, aes(group = Model, fill = Model, color = Model)) +
  geom_density(aes(x = exp(`logN_proj[2]`)), alpha = 0.4) +
  geom_rug(aes(x = threshold_N), color = "black", linewidth = 1.5) +
  geom_rug(aes(x = threshold_Nmin), color = "red", linewidth = 1.5) +
  # vline_at(threshold_N, linetype = 2) +
  # vline_at(threshold_Nmin, color = "red", linetype = 2) +
  geom_vline(data = postLastYr_mns, aes(xintercept = Nmean, group = Model, color = Model),
             alpha = 1, linewidth = 0.8, linetype = 3) +
  viridis::scale_fill_viridis(discrete = T, option = "B") +
  viridis::scale_color_viridis(discrete = T, option = "B") +
  scale_x_continuous(limits = c(0, 350)) +
  guides(color = guide_legend(title = NULL, position = "top", direction = "horizontal", nrow = 1),
         fill = guide_legend(title = NULL, position = "top", direction = "horizontal", nrow = 1)) +
  labs(x = "Projected N (Year 2024)", y = "Density") +
  theme_bw()
```
